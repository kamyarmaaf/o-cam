import React, { useState, useRef, useEffect } from 'react';
import * as faceapi from 'face-api.js';

const SimpleFaceTest: React.FC = () => {
  const [status, setStatus] = useState({
    modelsLoaded: false,
    cameraActive: false,
    videoReady: false,
    detecting: false
  });
  
  const [detectionResults, setDetectionResults] = useState({
    faceCount: 0,
    lastError: '',
    lastSuccess: '',
    videoInfo: {
      width: 0,
      height: 0,
      readyState: 0,
      paused: false,
      ended: false
    }
  });

  const [logs, setLogs] = useState<string[]>([]);
  const videoRef = useRef<HTMLVideoElement>(null);
  const streamRef = useRef<MediaStream | null>(null);

  const addLog = (message: string) => {
    console.log(`[SimpleTest] ${message}`);
    setLogs(prev => [...prev.slice(-19), `${new Date().toLocaleTimeString()}: ${message}`]);
  };

  const updateVideoInfo = () => {
    if (videoRef.current) {
      const video = videoRef.current;
      setDetectionResults(prev => ({
        ...prev,
        videoInfo: {
          width: video.videoWidth,
          height: video.videoHeight,
          readyState: video.readyState,
          paused: video.paused,
          ended: video.ended
        }
      }));
    }
  };

  // Load models
  const loadModels = async () => {
    try {
      addLog('Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§...');
      
      // Try local first
      try {
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
          faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
          faceapi.nets.faceRecognitionNet.loadFromUri('/models'),
        ]);
        addLog('âœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² Ù…Ø³ÛŒØ± Ù…Ø­Ù„ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯');
      } catch (localError) {
        addLog('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­Ù„ÛŒ: ' + localError);
        addLog('Ø¯Ø± Ø­Ø§Ù„ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ CDN...');
        
        // Fallback to CDN
        const base = 'https://justadudewhohacks.github.io/face-api.js/models';
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(base),
          faceapi.nets.faceLandmark68Net.loadFromUri(base),
          faceapi.nets.faceRecognitionNet.loadFromUri(base),
        ]);
        addLog('âœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø§Ø² CDN Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯');
      }
      
      setStatus(prev => ({ ...prev, modelsLoaded: true }));
      setDetectionResults(prev => ({ ...prev, lastSuccess: 'Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯' }));
    } catch (error) {
      addLog('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§: ' + error);
      setDetectionResults(prev => ({ ...prev, lastError: 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§: ' + error }));
    }
  };

  // Start camera
  const startCamera = async () => {
    try {
      addLog('Ø¯Ø± Ø­Ø§Ù„ Ø´Ø±ÙˆØ¹ Ø¯ÙˆØ±Ø¨ÛŒÙ†...');
      
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { 
          width: { ideal: 640 },
          height: { ideal: 480 },
          facingMode: 'user'
        }
      });
      
      streamRef.current = stream;
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.muted = true;
        videoRef.current.playsInline = true;
        
        videoRef.current.onloadedmetadata = async () => {
          addLog('âœ… Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯');
          updateVideoInfo();
          
          try {
            await videoRef.current?.play();
            addLog('âœ… ÙˆÛŒØ¯ÛŒÙˆ Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ù¾Ø®Ø´ Ú©Ø±Ø¯');
            
            // Wait a bit more for video to be truly ready
            setTimeout(() => {
              updateVideoInfo();
              if (videoRef.current && 
                  videoRef.current.videoWidth > 0 && 
                  videoRef.current.videoHeight > 0 &&
                  !videoRef.current.paused) {
                setStatus(prev => ({ ...prev, cameraActive: true, videoReady: true }));
                addLog('âœ… ÙˆÛŒØ¯ÛŒÙˆ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª');
              } else {
                addLog('âš ï¸ ÙˆÛŒØ¯ÛŒÙˆ Ù‡Ù†ÙˆØ² Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¢Ù…Ø§Ø¯Ù‡ Ù†ÛŒØ³Øª');
              }
            }, 1000);
          } catch (playError) {
            addLog('âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø®Ø´ ÙˆÛŒØ¯ÛŒÙˆ: ' + playError);
          }
        };
      }
    } catch (error) {
      addLog('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯ÙˆØ±Ø¨ÛŒÙ†: ' + error);
      setDetectionResults(prev => ({ ...prev, lastError: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯ÙˆØ±Ø¨ÛŒÙ†: ' + error }));
    }
  };

  // Stop camera
  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    setStatus(prev => ({ ...prev, cameraActive: false, videoReady: false }));
    addLog('Ø¯ÙˆØ±Ø¨ÛŒÙ† Ù…ØªÙˆÙ‚Ù Ø´Ø¯');
  };

  // Detect faces - simple version
  const detectFaces = async () => {
    if (!videoRef.current || !status.modelsLoaded) {
      addLog('âŒ ÙˆÛŒØ¯ÛŒÙˆ ÛŒØ§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ù†ÛŒØ³ØªÙ†Ø¯');
      setDetectionResults(prev => ({ 
        ...prev, 
        lastError: 'ÙˆÛŒØ¯ÛŒÙˆ ÛŒØ§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ù†ÛŒØ³ØªÙ†Ø¯' 
      }));
      return;
    }

    updateVideoInfo();
    
    const video = videoRef.current;
    
    // Detailed readiness check
    if (video.readyState < 2) {
      addLog('âŒ ÙˆÛŒØ¯ÛŒÙˆ Ø¢Ù…Ø§Ø¯Ù‡ Ù†ÛŒØ³Øª (readyState: ' + video.readyState + ')');
      setDetectionResults(prev => ({ 
        ...prev, 
        lastError: 'ÙˆÛŒØ¯ÛŒÙˆ Ø¢Ù…Ø§Ø¯Ù‡ Ù†ÛŒØ³Øª (readyState: ' + video.readyState + ')' 
      }));
      return;
    }
    
    if (video.videoWidth === 0 || video.videoHeight === 0) {
      addLog('âŒ Ø§Ø¨Ø¹Ø§Ø¯ ÙˆÛŒØ¯ÛŒÙˆ ØµÙØ± Ø§Ø³Øª');
      setDetectionResults(prev => ({ 
        ...prev, 
        lastError: 'Ø§Ø¨Ø¹Ø§Ø¯ ÙˆÛŒØ¯ÛŒÙˆ ØµÙØ± Ø§Ø³Øª' 
      }));
      return;
    }

    if (video.paused || video.ended) {
      addLog('âŒ ÙˆÛŒØ¯ÛŒÙˆ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø®Ø´ Ù†ÛŒØ³Øª');
      setDetectionResults(prev => ({ 
        ...prev, 
        lastError: 'ÙˆÛŒØ¯ÛŒÙˆ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø®Ø´ Ù†ÛŒØ³Øª' 
      }));
      return;
    }

    try {
      setStatus(prev => ({ ...prev, detecting: true }));
      addLog('Ø¯Ø± Ø­Ø§Ù„ ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡...');
      
      // Small delay to ensure video frame is ready
      await new Promise(resolve => setTimeout(resolve, 100));
      
      const options = new faceapi.TinyFaceDetectorOptions({ 
        inputSize: 320, 
        scoreThreshold: 0.3 
      });
      
      const results = await faceapi
        .detectAllFaces(video, options)
        .withFaceLandmarks()
        .withFaceDescriptors();

      const faceCount = results.length;
      addLog(`âœ… ${faceCount} Ú†Ù‡Ø±Ù‡ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯`);
      
      setDetectionResults(prev => ({
        ...prev,
        faceCount,
        lastSuccess: `${faceCount} Ú†Ù‡Ø±Ù‡ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯`,
        lastError: ''
      }));
      
    } catch (error) {
      addLog('âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡: ' + error);
      setDetectionResults(prev => ({ 
        ...prev, 
        lastError: 'Ø®Ø·Ø§ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡: ' + error 
      }));
    } finally {
      setStatus(prev => ({ ...prev, detecting: false }));
    }
  };

  // Auto-detect every 2 seconds when camera is active
  useEffect(() => {
    let interval: NodeJS.Timeout;
    
    if (status.cameraActive && status.videoReady && status.modelsLoaded) {
      interval = setInterval(() => {
        if (!status.detecting) {
          detectFaces();
        }
      }, 2000);
    }
    
    return () => {
      if (interval) clearInterval(interval);
    };
  }, [status.cameraActive, status.videoReady, status.modelsLoaded, status.detecting]);

  // Initial load
  useEffect(() => {
    loadModels();
    
    return () => {
      stopCamera();
    };
  }, []);

  return (
    <div className="min-h-screen bg-gray-100 p-4">
      <div className="max-w-6xl mx-auto">
        <h1 className="text-2xl font-bold text-center mb-6">ØªØ³Øª Ø³Ø§Ø¯Ù‡ ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡</h1>
        
        <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
          {/* Left Panel - Video and Controls */}
          <div className="bg-white rounded-lg shadow-lg p-6">
            <h2 className="text-lg font-semibold mb-4">Ø¯ÙˆØ±Ø¨ÛŒÙ† Ùˆ Ú©Ù†ØªØ±Ù„â€ŒÙ‡Ø§</h2>
            
            {/* Status Indicators */}
            <div className="grid grid-cols-2 gap-3 mb-4">
              <div className={`p-3 rounded text-center text-sm ${
                status.modelsLoaded ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'
              }`}>
                Ù…Ø¯Ù„â€ŒÙ‡Ø§: {status.modelsLoaded ? 'âœ… Ø¢Ù…Ø§Ø¯Ù‡' : 'âŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡'}
              </div>
              <div className={`p-3 rounded text-center text-sm ${
                status.cameraActive ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'
              }`}>
                Ø¯ÙˆØ±Ø¨ÛŒÙ†: {status.cameraActive ? 'âœ… ÙØ¹Ø§Ù„' : 'âŒ ØºÛŒØ±ÙØ¹Ø§Ù„'}
              </div>
              <div className={`p-3 rounded text-center text-sm ${
                status.videoReady ? 'bg-green-100 text-green-800' : 'bg-yellow-100 text-yellow-800'
              }`}>
                ÙˆÛŒØ¯ÛŒÙˆ: {status.videoReady ? 'âœ… Ø¢Ù…Ø§Ø¯Ù‡' : 'â³ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ'}
              </div>
              <div className={`p-3 rounded text-center text-sm ${
                status.detecting ? 'bg-blue-100 text-blue-800' : 'bg-gray-100 text-gray-800'
              }`}>
                ØªØ´Ø®ÛŒØµ: {status.detecting ? 'ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…' : 'â¸ï¸ Ù…ØªÙˆÙ‚Ù'}
              </div>
            </div>

            {/* Video */}
            <div className="mb-4">
              <video
                ref={videoRef}
                autoPlay
                playsInline
                muted
                className="w-full h-48 bg-black rounded-lg object-cover"
                style={{ transform: 'scaleX(-1)' }}
              />
            </div>

            {/* Video Info */}
            <div className="bg-gray-50 p-3 rounded-lg mb-4 text-sm">
              <h3 className="font-semibold mb-2">Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÛŒØ¯ÛŒÙˆ:</h3>
              <div className="grid grid-cols-2 gap-2 text-xs">
                <div>Ø¹Ø±Ø¶: {detectionResults.videoInfo.width}</div>
                <div>Ø§Ø±ØªÙØ§Ø¹: {detectionResults.videoInfo.height}</div>
                <div>ReadyState: {detectionResults.videoInfo.readyState}</div>
                <div>Paused: {detectionResults.videoInfo.paused ? 'Yes' : 'No'}</div>
              </div>
            </div>

            {/* Controls */}
            <div className="flex flex-wrap gap-2">
              <button
                onClick={startCamera}
                disabled={status.cameraActive || !status.modelsLoaded}
                className="px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 disabled:bg-gray-400 text-sm"
              >
                Ø´Ø±ÙˆØ¹ Ø¯ÙˆØ±Ø¨ÛŒÙ†
              </button>
              <button
                onClick={stopCamera}
                disabled={!status.cameraActive}
                className="px-4 py-2 bg-red-600 text-white rounded hover:bg-red-700 disabled:bg-gray-400 text-sm"
              >
                ØªÙˆÙ‚Ù Ø¯ÙˆØ±Ø¨ÛŒÙ†
              </button>
              <button
                onClick={detectFaces}
                disabled={!status.cameraActive || !status.videoReady || !status.modelsLoaded || status.detecting}
                className="px-4 py-2 bg-green-600 text-white rounded hover:bg-green-700 disabled:bg-gray-400 text-sm"
              >
                ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡
              </button>
              <button
                onClick={() => setLogs([])}
                className="px-4 py-2 bg-gray-600 text-white rounded hover:bg-gray-700 text-sm"
              >
                Ù¾Ø§Ú© Ù„Ø§Ú¯â€ŒÙ‡Ø§
              </button>
            </div>

            {/* Results */}
            <div className="mt-4 space-y-2">
              <div className="bg-blue-50 p-3 rounded-lg">
                <span className="text-sm font-medium">ØªØ¹Ø¯Ø§Ø¯ Ú†Ù‡Ø±Ù‡â€ŒÙ‡Ø§: </span>
                <span className="text-lg font-bold">{detectionResults.faceCount}</span>
              </div>
              
              {detectionResults.lastSuccess && (
                <div className="bg-green-50 p-3 rounded-lg">
                  <span className="text-sm text-green-800">{detectionResults.lastSuccess}</span>
                </div>
              )}
              
              {detectionResults.lastError && (
                <div className="bg-red-50 p-3 rounded-lg">
                  <span className="text-sm text-red-800">{detectionResults.lastError}</span>
                </div>
              )}
            </div>
          </div>

          {/* Right Panel - Logs */}
          <div className="bg-white rounded-lg shadow-lg p-6">
            <h2 className="text-lg font-semibold mb-4">Ù„Ø§Ú¯â€ŒÙ‡Ø§</h2>
            
            <div className="bg-black text-green-400 p-4 rounded-lg h-96 overflow-y-auto font-mono text-xs">
              {logs.length === 0 ? (
                <div className="text-gray-500">Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± ÙØ¹Ø§Ù„ÛŒØª...</div>
              ) : (
                logs.map((log, index) => (
                  <div key={index} className="mb-1">
                    {log}
                  </div>
                ))
              )}
            </div>
            
            <div className="mt-4 text-sm text-gray-600">
              <p className="font-semibold mb-2">Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡:</p>
              <ol className="list-decimal list-inside space-y-1">
                <li>Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯ ØªØ§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´ÙˆÙ†Ø¯</li>
                <li>Ø±ÙˆÛŒ "Ø´Ø±ÙˆØ¹ Ø¯ÙˆØ±Ø¨ÛŒÙ†" Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯</li>
                <li>Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯ ØªØ§ ÙˆÛŒØ¯ÛŒÙˆ Ø¢Ù…Ø§Ø¯Ù‡ Ø´ÙˆØ¯</li>
                <li>ØªØ´Ø®ÛŒØµ Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ù‡Ø± 2 Ø«Ø§Ù†ÛŒÙ‡ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯</li>
                <li>ÛŒØ§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ Ø±ÙˆÛŒ "ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡" Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯</li>
              </ol>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
};

export default SimpleFaceTest;